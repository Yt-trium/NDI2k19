{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\n%matplotlib inline","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","execution_count":2,"outputs":[{"output_type":"stream","text":"2.1.0-rc0\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\"\"\"\nfrom IPython.core.display import display, HTML\nfrom PIL import Image\nfrom io import BytesIO\nimport base64\n\"\"\"","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"'\\nfrom IPython.core.display import display, HTML\\nfrom PIL import Image\\nfrom io import BytesIO\\nimport base64\\n'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_folder = '../input/celeba-dataset/'\nimages_folder = main_folder + 'img_align_celeba/img_align_celeba/'\n\nEXAMPLE_PIC = images_folder + '000506.jpg'\n\nTRAINING_SAMPLES = 40000\nVALIDATION_SAMPLES = 2000\nTEST_SAMPLES = 2000\nIMG_WIDTH = 178\nIMG_HEIGHT = 218\nBATCH_SIZE = 16\nNUM_EPOCHS = 20","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the data set that include the attribute for each picture\ndf_attr = pd.read_csv(main_folder + 'list_attr_celeba.csv')\ndf_attr.set_index('image_id', inplace=True)\ndf_attr.replace(to_replace=-1, value=0, inplace=True) #replace -1 by 0\ndf_attr.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(202599, 40)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image = np.zeros((TRAINING_SAMPLES, 218, 178, 3), dtype=np.uint8)\n\nfor i in range(0, TRAINING_SAMPLES):\n    train_image[i,:,:,:] = cv2.imread(images_folder + str(i+1).zfill(6) + \".jpg\")/255","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gd = np.zeros((TRAINING_SAMPLES, 1), dtype=np.uint8)\n\nfor i in range(0, TRAINING_SAMPLES):\n    train_gd[i] = df_attr.loc[str(i+1).zfill(6)+\".jpg\"]['Smiling']","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_image = np.zeros((VALIDATION_SAMPLES, 218, 178, 3), dtype=np.uint8)\n\nfor i in range(0, VALIDATION_SAMPLES):\n    valid_image[i,:,:,:] = cv2.imread(images_folder + str(i+1+TRAINING_SAMPLES).zfill(6) + \".jpg\")/255\n\nvalid_gd = np.zeros((VALIDATION_SAMPLES, 1), dtype=np.uint8)\n\nfor i in range(0, VALIDATION_SAMPLES):\n    valid_gd[i] = df_attr.loc[str(i+1+TRAINING_SAMPLES).zfill(6)+\".jpg\"]['Smiling']","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(218, 178, 3)))\nmodel.add(tf.keras.layers.MaxPooling2D((2, 2)))\nmodel.add(tf.keras.layers.SpatialDropout2D(0.1))\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D((2, 2)))\nmodel.add(tf.keras.layers.SpatialDropout2D(0.1))\nmodel.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(8, activation='relu'))\n#model.add(tf.keras.layers.Dense(2, activation='softmax'))\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","execution_count":9,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 216, 176, 32)      896       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 108, 88, 32)       0         \n_________________________________________________________________\nspatial_dropout2d (SpatialDr (None, 108, 88, 32)       0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 106, 86, 64)       18496     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 53, 43, 64)        0         \n_________________________________________________________________\nspatial_dropout2d_1 (Spatial (None, 53, 43, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 51, 41, 128)       73856     \n_________________________________________________________________\nflatten (Flatten)            (None, 267648)            0         \n_________________________________________________________________\ndense (Dense)                (None, 8)                 2141192   \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 9         \n=================================================================\nTotal params: 2,234,449\nTrainable params: 2,234,449\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.input_shape","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"(None, 218, 178, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_image, train_gd, validation_data=(valid_image, valid_gd), epochs=15)","execution_count":11,"outputs":[{"output_type":"stream","text":"Train on 40000 samples, validate on 2000 samples\nEpoch 1/15\n40000/40000 [==============================] - 39s 984us/sample - loss: 0.5717 - accuracy: 0.6753 - val_loss: 0.5476 - val_accuracy: 0.6900\nEpoch 2/15\n40000/40000 [==============================] - 31s 773us/sample - loss: 0.5090 - accuracy: 0.7165 - val_loss: 0.5481 - val_accuracy: 0.6850\nEpoch 3/15\n40000/40000 [==============================] - 31s 763us/sample - loss: 0.4425 - accuracy: 0.7580 - val_loss: 0.5963 - val_accuracy: 0.6660\nEpoch 4/15\n40000/40000 [==============================] - 30s 743us/sample - loss: 0.3521 - accuracy: 0.8106 - val_loss: 0.6664 - val_accuracy: 0.6520\nEpoch 5/15\n40000/40000 [==============================] - 30s 745us/sample - loss: 0.2637 - accuracy: 0.8586 - val_loss: 1.0135 - val_accuracy: 0.6575\nEpoch 6/15\n40000/40000 [==============================] - 30s 745us/sample - loss: 0.2086 - accuracy: 0.8835 - val_loss: 1.2052 - val_accuracy: 0.6560\nEpoch 7/15\n40000/40000 [==============================] - 30s 750us/sample - loss: 0.1818 - accuracy: 0.8986 - val_loss: 1.3857 - val_accuracy: 0.6630\nEpoch 8/15\n40000/40000 [==============================] - 30s 745us/sample - loss: 0.1639 - accuracy: 0.9099 - val_loss: 1.7456 - val_accuracy: 0.6640\nEpoch 9/15\n40000/40000 [==============================] - 30s 744us/sample - loss: 0.1557 - accuracy: 0.9128 - val_loss: 1.8064 - val_accuracy: 0.6605\nEpoch 10/15\n40000/40000 [==============================] - 30s 748us/sample - loss: 0.1477 - accuracy: 0.9165 - val_loss: 1.7227 - val_accuracy: 0.6565\nEpoch 11/15\n40000/40000 [==============================] - 30s 760us/sample - loss: 0.1425 - accuracy: 0.9194 - val_loss: 2.2201 - val_accuracy: 0.6560\nEpoch 12/15\n40000/40000 [==============================] - 31s 770us/sample - loss: 0.1386 - accuracy: 0.9199 - val_loss: 2.6315 - val_accuracy: 0.6545\nEpoch 13/15\n40000/40000 [==============================] - 31s 763us/sample - loss: 0.1336 - accuracy: 0.9228 - val_loss: 2.2369 - val_accuracy: 0.6585\nEpoch 14/15\n40000/40000 [==============================] - 31s 765us/sample - loss: 0.1302 - accuracy: 0.9238 - val_loss: 2.3930 - val_accuracy: 0.6470\nEpoch 15/15\n40000/40000 [==============================] - 30s 759us/sample - loss: 0.1315 - accuracy: 0.9235 - val_loss: 2.3304 - val_accuracy: 0.6545\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f43ad5aac18>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"model.h5\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}